{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lucas_distilbert-base-uncased_A.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DianaMoyano1/NLP-Sentiment_Extraction_Challenge/blob/master/Lucas_distilbert_base_uncased_A_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGR6ljGnRWL",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 1: Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SclTK2sEy2U",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#install the following first\n",
        "!pip install transformers==2.11.0 --quiet\n",
        "!pip install tensorflow==2.2.0 --quiet\n",
        "!pip install tensorboardX --quiet\n",
        "!pip install simpletransformers --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-f6h_O-ax7b",
        "colab_type": "text"
      },
      "source": [
        "### Setup NVIDIA APEX\n",
        "\n",
        "Tool to enable mixed precision training. More info here: https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EKbT79HZ1FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile setup.sh\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8BU4o8aAxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will take 10mins to run\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "!sh setup.sh --quiet\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sonPGlnWahCx",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6XzV6-3RTGe",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#Import packages\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from apex import amp\n",
        "from glob import glob\n",
        "import os\n",
        "from random import random\n",
        "from pathlib import Path\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TFBertModel, BertModel, DistilBertModel, XLNetModel, RobertaModel\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from os.path import join\n",
        "\n",
        "\n",
        "use_cuda = True ##If True, GPU will be used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPBTI365dJLo",
        "colab_type": "text"
      },
      "source": [
        "### Mount Your Own Gdrive\n",
        "\n",
        "Below command will require you to validate your account, and it will provide you with a temporary access code to paste in the required field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-bkv7WRK7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7T-lNV39yOJ",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94gEgYzgV72",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Before running below command, make sure you have...\n",
        "- Created a *'tweet-sentiment-extraction'* folder inside the *'Colab Notebooks'* directory\n",
        "- Uploaded the *train.csv* and *test.csv* files to the *'tweet-sentiment-extraction'* folder \n",
        "\n",
        "Finally, make sure you have a folder called *'models'* inside the *'tweet-sentiment-extraction'* directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1aa6YfTGJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/train.csv')\n",
        "test_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/test.csv')\n",
        "\n",
        "\n",
        "\n",
        "#sub_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/sample_submission.csv') #Optional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho6qQLOmzy7-",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data\n",
        "\n",
        "Split into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEEY7JDVBRrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnE_Tgqlcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop selected_text column from the validation dataset (it will be later compared to the ground truth)\n",
        "val_df_new = val_df.drop('selected_text', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8FMKmbQF7au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape)\n",
        "print(val_df_new.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBON4Ni8GSpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.array(train_df)\n",
        "val = np.array(val_df_new)\n",
        "test = np.array(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFB0LNoZ9C-1",
        "colab_type": "text"
      },
      "source": [
        "### Initiate the SimpleTransformers Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBRBDPcT7oTQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The SimpleTransformers library supports numerous tasks:  \n",
        "\n",
        "\n",
        "- Sequence Classification\n",
        "- Token Classification (NER)\n",
        "- Question Answering\n",
        "- Language Model Fine-Tuning\n",
        "- Language Model Training\n",
        "- Language Generation\n",
        "- T5 Model\n",
        "- Seq2Seq Tasks\n",
        "- Multi-Modal Classification\n",
        "- Conversational AI\n",
        "\n",
        "In this case, we are performing a <ins>Question&Answer</ins> task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln6FNmWRJlJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simpletransformers.question_answering import QuestionAnsweringModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0y9mIBG8ax2",
        "colab_type": "text"
      },
      "source": [
        "### Format the data under the SimpleTransformer's *Question&Answer* schema "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfvz-pl1a4u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "To input the dataset, we need to assign each column to specific inputs\n",
        "- Context: The entire tweet\n",
        "- Question: The sentiment (positive, negative or neutral). In other words, we are asking *\\\"What part of the entire tweet best represents this sentiment?\\\"*\n",
        "- Answer: the label - the extracted text\n",
        "\n",
        "The formated data is assigned to the variables *qa_train, qa_val* and *qa_test* respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvWbeYDGPT-P",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create list for training\n",
        "\n",
        "## Adpated from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def find_all(input_str, search_str):\n",
        "    l1 = []\n",
        "    length = len(input_str)\n",
        "    index = 0\n",
        "    while index < length:\n",
        "        i = input_str.find(search_str, index)\n",
        "        if i == -1:\n",
        "            return l1\n",
        "        l1.append(i)\n",
        "        index = i + 1\n",
        "    return l1\n",
        "\n",
        "def do_qa_train(train):\n",
        "\n",
        "    output = []\n",
        "    for line in train:\n",
        "        context = line[1]\n",
        "\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        answers = []\n",
        "        answer = line[2]\n",
        "        if type(answer) != str or type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answer_starts = find_all(context, answer)\n",
        "        for answer_start in answer_starts:\n",
        "            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n",
        "            break\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "        \n",
        "    return output\n",
        "\n",
        "qa_train = do_qa_train(train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD6Jk6WXHHx0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create val list\n",
        "def do_qa_val(val):\n",
        "    output = []\n",
        "    for line in val:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_val = do_qa_val(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nUa3ClTU3t",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create test list\n",
        "def do_qa_test(test):\n",
        "    output = []\n",
        "    for line in test:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_test = do_qa_test(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DsYbQI18gP7",
        "colab_type": "text"
      },
      "source": [
        "### Create a Logging Module --> More info [here](https://realpython.com/python-logging/#:~:text=The%20Logging%20Module,-The%20logging%20module&text=It%20is%20used%20by%20most,homogeneous%20log%20for%20your%20application.&text=With%20the%20logging%20module%20imported,that%20you%20want%20to%20see.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7kc0kuO5oF4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Logs provide developers with an extra set of eyes that are constantly looking at the flow that an application is going through. They can store information, like which user or IP accessed the application.  \n",
        "\n",
        "With the logging module imported, you can use something called a “logger” to log messages that you want to see. By default, there are 5 standard levels indicating the severity of events.\n",
        "- DEBUG\n",
        "- INFO\n",
        "- WARNING\n",
        "- ERROR\n",
        "- CRITICAL\n",
        "\n",
        "In this case, we picked INFO and WARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-18PYUqo4yLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipp8nNzF8lMT",
        "colab_type": "text"
      },
      "source": [
        "### Train a SimpleTransformers Model **<ins>OR</ins>** Load an Existing Richardson Model  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDWKx09SfXMp",
        "colab_type": "text"
      },
      "source": [
        "Select the option that best applies to your case.  \n",
        "\n",
        "\n",
        ">#### Option 1: Train a SimpleTransformers Model\n",
        "\n",
        ">1. Create a folder that will contain the new model's PyTorch and hyperameters files. Follow below instructions to assign a name to the *'NAME_OF_MODEL'*  folder:\n",
        "\n",
        "\n",
        ">>>**Basic Structure:**\n",
        "\n",
        ">>>\\<Name>_\\<Model>_\\<Version>  \n",
        "\n",
        ">>>>Where:\n",
        "- Name: Your name\n",
        "- Model: Based on the model names used in the official Transformers site: https://huggingface.co/transformers/pretrained_models.html\n",
        "- Version: For notebooks with same name and model but different hyperparameters, include the version (A, B, C...)\n",
        "  \n",
        "  >>>>Examples:\n",
        "  - Lucas_distilroberta-base_A\n",
        "  - Lucas_distilroberta-base_B\n",
        "  - Landis_bert_A  \n",
        "\n",
        ">2. Follow **SECTION 2**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "  >#### Option 2: Load an Existing Richardson Model\n",
        "\n",
        "  >1. Under *'NAME_OF_MODEL'*, enter the name of the model folder you want to load\n",
        "  >2. Skip *SECTION 2* and follow **SECTION 3**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaUrF49NHrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME_OF_MODEL = 'Diana_bert-base-cased_A' ## TODO --> Change this"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ-uW7IvYHH1",
        "colab_type": "text"
      },
      "source": [
        "#### Next Steps\n",
        "A this point, you should be saving your work:\n",
        "\n",
        "1. Save a copy of this notebook in GitHub with the same name you used under *'NAME_OF_MODEL'* \n",
        "2. Go to the Experiments project and add a note with the following info\n",
        "\n",
        "\n",
        ">*   Name you enter under NAME_OF_MODEL\n",
        ">*   Jaccard Score (once you have it)\n",
        ">*   List of arguments (you'll find them in SECTION 2 under <ins>**args_train**</ins>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu8C-zphp9DP",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 2: Load, train and evaluate a SimpleTransformers Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDEYgbSKpC9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Don't change this\n",
        "\n",
        "ROOT = '/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/models' \n",
        "\n",
        "FULL_PATH = join(ROOT, NAME_OF_MODEL)\n",
        "\n",
        "#Change the workspace to the \"tweet-sentiment-extraction/models\" folder\n",
        "%cd '{ROOT}'\n",
        "#It creates the folder where the model components will be saved. If you have a folder with the same name, it will give you an error\n",
        "%mkdir '{NAME_OF_MODEL}' \n",
        "#Change the workspace to the recently created folder\n",
        "%cd '{FULL_PATH}' \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTC_2IcRKmH4",
        "colab_type": "text"
      },
      "source": [
        "Supported model types for Question&Answering:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet\n",
        "\n",
        "Related link: https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlWY8Y7MYSmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For more arguments, refer to this link --> https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model\n",
        "\n",
        "args_train={'reprocess_input_data': True,\n",
        "'overwrite_output_dir': True,\n",
        "'learning_rate': 5e-5,\n",
        "'num_train_epochs': 1,\n",
        "'max_seq_length': 192,\n",
        "'doc_stride': 64,\n",
        "'fp16': False,\n",
        "}\n",
        "\n",
        "model = QuestionAnsweringModel('bert', 'bert-base-cased', args=args_train, use_cuda=use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdo6wnSdYJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "model.train_model(qa_train)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttTEa5vskmCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "predictions_val = model.predict(qa_val)\n",
        "predictions_test = model.predict(qa_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_ZrfqQNkHA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)\n",
        "#test\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1NXIUmhU64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSOuQa19ntpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUB5FeXMhXbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create files to export \n",
        "sub_val_df['selected_text_results'] = text2_val[0].values\n",
        "sub_test_df['selected_text_results'] = text2_test[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrjMaEA8m_gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne55UzM9DppA",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model arguments and other files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ln-OCSbUtAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XifqXffjlGqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This line creates a JSON file that is required when loading the model\n",
        "with open('args_train.json', 'w') as fp: \n",
        "    json.dump(args_train, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDE_EE42bEW1",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 3: Load and Evaluate a Richardson's Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pHXf7bq9Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ROOT = '/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/models' #Don't change\n",
        "\n",
        "FULL_PATH = join(ROOT, NAME_OF_MODEL)\n",
        "\n",
        "#Change the workspace to the model folder\n",
        "%cd '{FULL_PATH}' \n",
        "\n",
        "#Load the model's arguments list (required to setup the existing model) \n",
        "with open('args_train.json') as json_file: \n",
        "    train_args = json.load(json_file) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiDki8xbA4ZY",
        "colab_type": "text"
      },
      "source": [
        "#### Setup loaded model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZCmZyVANve",
        "colab_type": "text"
      },
      "source": [
        "Supported model types for Question&Answering:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet\n",
        "\n",
        "Related link: https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaLA-2ibEBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = QuestionAnsweringModel('bert', 'outputs/', args=train_args, use_cuda=use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOWk-YAeKw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val = loaded_model.predict(qa_val)\n",
        "predictions_test = loaded_model.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvqhWsD_y_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)\n",
        "#test\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnPM7OF9eQAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-rGNG_FeV_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OOmUWMfeaSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create files to export \n",
        "sub_val_df['selected_text_results'] = text2_val[0].values\n",
        "sub_test_df['selected_text_results'] = text2_test[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh0IHQsMIRwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}