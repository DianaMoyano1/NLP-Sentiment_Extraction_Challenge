{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_SingleM_Template - Eman check",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DianaMoyano1/NLP-Sentiment_Extraction_Challenge/blob/master/Tutorial_SingleM_Template_Eman_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGR6ljGnRWL",
        "colab_type": "text"
      },
      "source": [
        "# SETUP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnOkICFeQxsY",
        "colab_type": "text"
      },
      "source": [
        "1. Click on Runtime --> Change runtime type\n",
        "2. Select **GPU** under *Hardware accelerator*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94gEgYzgV72",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Before running this notebook, make sure you have added the *'tweet-sentiment-extraction-tutorial'* shortcut to your Gdrive, inside the *'Colab Notebooks'* directory\n",
        "\n",
        "![](https://serving.photos.photobox.com/817973499a3406a94b0556385350836dda810c16c1a20967bd25b50dd6e367b3dcb1e30b.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPBTI365dJLo",
        "colab_type": "text"
      },
      "source": [
        "### Mount Your Own Gdrive\n",
        "\n",
        "Below command will require you to validate your account, and it will provide you with a temporary access code to paste in the field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-bkv7WRK7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount your local Google drive and show the models you have\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls '/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/models' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SclTK2sEy2U",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#install the following packages. The --quiet command will reduce the output lines\n",
        "!pip install transformers==2.11.0 --quiet\n",
        "!pip install tensorflow==2.2.0 --quiet\n",
        "!pip install tensorboardX --quiet\n",
        "!pip install simpletransformers --quiet\n",
        "!pip install chart_studio --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-f6h_O-ax7b",
        "colab_type": "text"
      },
      "source": [
        "### Setup NVIDIA APEX\n",
        "\n",
        "Tool to enable mixed precision training in Pytorch (the underlying structure for SimpleTransformers). More info here: https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EKbT79HZ1FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile setup.sh\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8BU4o8aAxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will take 7-10 mins to run\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "!sh setup.sh --quiet\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sonPGlnWahCx",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6XzV6-3RTGe",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#Import packages\n",
        "from os.path import join\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from apex import amp\n",
        "import json\n",
        "\n",
        "\n",
        "use_cuda = True ##If True, GPU will be used"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7T-lNV39yOJ",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1aa6YfTGJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/train.csv')\n",
        "test_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS794cV0XDL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQpFNQnWXFqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cDvYTni9nFu",
        "colab_type": "text"
      },
      "source": [
        "# EXPLORATORY DATA ANALYSIS (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwY83wEz9sy-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Import Packages\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Visualisation libraries\n",
        "import matplotlib.pyplot as plt \n",
        "import plotly.graph_objs as go\n",
        "import chart_studio.plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.offline import iplot\n",
        "import cufflinks\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
        "\n",
        "# sklearn \n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "#Text Pre-processing\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# Suppress warnings \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X03dMjka9wst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make a copy of the original datasets for visualization purposes\n",
        "train = train_df.copy()\n",
        "test = test_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmPj9HpYAG7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def enable_plotly_in_cell():\n",
        "  import IPython\n",
        "  from plotly.offline import init_notebook_mode\n",
        "  display(IPython.core.display.HTML('''<script src=\"/static/components/requirejs/require.js\"></script>'''))\n",
        "  init_notebook_mode(connected=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jv-uJLbALcf",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Sentiment Distribution\n",
        "\n",
        "\n",
        "# Sentiment distribution in training set\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "train['sentiment'].value_counts(normalize=True).iplot(kind='bar',\n",
        "                                                      yTitle='Percentage', \n",
        "                                                      linecolor='black', \n",
        "                                                      opacity=0.7,\n",
        "                                                      color='red',\n",
        "                                                      theme='pearl',\n",
        "                                                      bargap=0.6,\n",
        "                                                      gridcolor='white',\n",
        "                                                      dimensions=(1000,500),\n",
        "                                                     \n",
        "                                                      title='Distribution of Sentiment column in the training set')\n",
        "\n",
        "\n",
        "# Sentiment distribution in test set\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "test['sentiment'].value_counts(normalize=True).iplot(kind='bar', \n",
        "                                                      linecolor='black', \n",
        "                                                      opacity=0.7,\n",
        "                                                      color='blue',\n",
        "                                                      theme='pearl',\n",
        "                                                      bargap=0.6,\n",
        "                                                      gridcolor='white',\n",
        "                                                      dimensions=(1000,500),\n",
        "                                                      title='Distribution  of Sentiment column in the test set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_SO-rdQCcEA",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Text Pre-processing Functions\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    #text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def text_preprocessing(text):\n",
        "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "    nopunc = clean_text(text)\n",
        "    tokenized_text = tokenizer.tokenize(nopunc)\n",
        "    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n",
        "    combined_text = ' '.join(tokenized_text)\n",
        "    return combined_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xx6BqKPLKyc",
        "colab_type": "text"
      },
      "source": [
        "### Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZAXTu4VEAmQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Applying the cleaning function to the training dataset\n",
        "train['text_clean'] = train['text'].apply(str).apply(lambda x: text_preprocessing(x))\n",
        "test['text_clean'] = test['text'].apply(str).apply(lambda x: text_preprocessing(x))\n",
        "\n",
        "train['text_len'] = train['text_clean'].astype(str).apply(len)\n",
        "train['text_word_count'] = train['text_clean'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "pos = train[train['sentiment']=='positive']\n",
        "neg = train[train['sentiment']=='negative']\n",
        "neutral = train[train['sentiment']=='neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U9QR8dIEjwF",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Box Plots\n",
        "# Text length box plot\n",
        "\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "trace0 = go.Box(\n",
        "    y=pos['text_len'],\n",
        "    name = 'Positive Text',\n",
        "    marker = dict(\n",
        "        color = 'blue',\n",
        "    )\n",
        ")\n",
        "\n",
        "trace1 = go.Box(\n",
        "    y=neg['text_len'],\n",
        "    name = 'Negative Text',\n",
        "    marker = dict(\n",
        "        color = 'red',\n",
        "    )\n",
        ")\n",
        "\n",
        "trace2 = go.Box(\n",
        "    y=neutral['text_len'],\n",
        "    name = 'Neutral Text',\n",
        "    marker = dict(\n",
        "        color = 'orange',\n",
        "    )\n",
        ")\n",
        "data = [trace0, trace1, trace2]\n",
        "layout = go.Layout(\n",
        "    title = \"Length of the text\"\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data,layout=layout)\n",
        "iplot(fig, filename = \"Length of the text of different polarities\")\n",
        "\n",
        "\n",
        "#Word count box plot\n",
        "\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "trace0 = go.Box(\n",
        "    y=pos['text_word_count'],\n",
        "    name = 'Positive Text',\n",
        "    marker = dict(\n",
        "        color = 'blue',\n",
        "    )\n",
        ")\n",
        "\n",
        "trace1 = go.Box(\n",
        "    y=neg['text_word_count'],\n",
        "    name = 'Negative Text',\n",
        "    marker = dict(\n",
        "        color = 'red',\n",
        "    )\n",
        ")\n",
        "\n",
        "trace2 = go.Box(\n",
        "    y=neutral['text_word_count'],\n",
        "    name = 'Neutral Text',\n",
        "    marker = dict(\n",
        "        color = 'orange',\n",
        "    )\n",
        ")\n",
        "data = [trace0, trace1, trace2]\n",
        "layout = go.Layout(\n",
        "    title = \"word count of the text\"\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data,layout=layout)\n",
        "iplot(fig, filename = \"word count of the text of different polarities\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x1rfgxAIaxS",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Function: Get Top K-Words\n",
        "#source of code : https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d\n",
        "def get_top_k_words(corpus, n=None):\n",
        "\n",
        "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z76XsX73Idhw",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Top 20 Words per Sentiment\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "pos_unigrams = get_top_k_words(pos['text_clean'],20)\n",
        "neg_unigrams = get_top_k_words(neg['text_clean'],20)\n",
        "neutral_unigrams = get_top_k_words(neutral['text_clean'],20)\n",
        "\n",
        "\n",
        "df1 = pd.DataFrame(pos_unigrams, columns = ['Text' , 'count'])\n",
        "df1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black',color='blue', title='Positive Sentiment',orientation='h')\n",
        "\n",
        "df2 = pd.DataFrame(neg_unigrams, columns = ['Text' , 'count'])\n",
        "df2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black', color='red',title='Negative Sentiment',orientation='h')\n",
        "\n",
        "df3 = pd.DataFrame(neutral_unigrams, columns = ['Text' , 'count'])\n",
        "df3.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black', title='Neutral Sentiment',orientation='h')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su9q5mimNGRU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Function: Top N-Grams Function \n",
        "def get_top_n_gram(corpus,ngram_range,n=None):\n",
        "    vec = CountVectorizer(ngram_range=ngram_range,stop_words = 'english').fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxTC_YigOSxj",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Top 20 Bi-grams\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "pos_bigrams = get_top_n_gram(pos['text_clean'],(2,2),20)\n",
        "neg_bigrams = get_top_n_gram(neg['text_clean'],(2,2),20)\n",
        "neutral_bigrams = get_top_n_gram(neutral['text_clean'],(2,2),20)\n",
        "\n",
        "\n",
        "\n",
        "#for word, freq in top_bigrams:\n",
        "    #print(word, freq)\n",
        "df1 = pd.DataFrame(pos_bigrams, columns = ['Text' , 'count'])\n",
        "df1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black',color='blue', title='Top 20 Bigrams in positve text',orientation='h')\n",
        "\n",
        "df2 = pd.DataFrame(neg_bigrams, columns = ['Text' , 'count'])\n",
        "df2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black', color='red',title='Top 20 Bigrams in negative text',orientation='h')\n",
        "\n",
        "df3 = pd.DataFrame(neutral_bigrams, columns = ['Text' , 'count'])\n",
        "df3.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 Bigrams in neutral text',orientation='h')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Rf7uRmPClK",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Top 20 Tri-grams\n",
        "\n",
        "enable_plotly_in_cell()\n",
        "\n",
        "pos_trigrams = get_top_n_gram(pos['text_clean'],(3,3),20)\n",
        "neg_trigrams = get_top_n_gram(neg['text_clean'],(3,3),20)\n",
        "neutral_trigrams = get_top_n_gram(neutral['text_clean'],(3,3),20)\n",
        "\n",
        "df1 = pd.DataFrame(pos_trigrams, columns = ['Text' , 'count'])\n",
        "df1.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black',color='blue', title='Top 20 Trigrams in positve text',orientation='h')\n",
        "\n",
        "df2 = pd.DataFrame(neg_trigrams, columns = ['Text' , 'count'])\n",
        "df2.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black', color='red',title='Top 20 Trigrams in negative text',orientation='h')\n",
        "\n",
        "df3 = pd.DataFrame(neutral_trigrams, columns = ['Text' , 'count'])\n",
        "df3.groupby('Text').sum()['count'].sort_values(ascending=True).iplot(\n",
        "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 Trigrams in neutral text',orientation='h')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZZLQ-vjPiq5",
        "colab_type": "text"
      },
      "source": [
        "### Word Clouds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtwlfNtMPiMg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Word Cloud Data Prep\n",
        "positive_text = train[train['sentiment'] == 'positive']['selected_text']\n",
        "negative_text = train[train['sentiment'] == 'negative']['selected_text']\n",
        "neutral_text = train[train['sentiment'] == 'neutral']['selected_text']\n",
        "\n",
        "positive_text_clean = positive_text.apply(lambda x: text_preprocessing(x))\n",
        "negative_text_clean = negative_text.apply(lambda x: text_preprocessing(x))\n",
        "neutral_text_clean = neutral_text.apply(lambda x: text_preprocessing(x))\n",
        "\n",
        "\n",
        "#Apply the top_n_words function\n",
        "\n",
        "top_words_in_positive_text = get_top_k_words(positive_text_clean)\n",
        "top_words_in_negative_text = get_top_k_words(negative_text_clean)\n",
        "top_words_in_neutral_text = get_top_k_words(neutral_text_clean)\n",
        "\n",
        "p1 = [x[0] for x in top_words_in_positive_text[:20]]\n",
        "p2 = [x[1] for x in top_words_in_positive_text[:20]]\n",
        "\n",
        "\n",
        "n1 = [x[0] for x in top_words_in_negative_text[:20]]\n",
        "n2 = [x[1] for x in top_words_in_negative_text[:20]]\n",
        "\n",
        "\n",
        "nu1 = [x[0] for x in top_words_in_neutral_text[:20]]\n",
        "nu2 = [x[1] for x in top_words_in_neutral_text[:20]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gNw4jiSRo_7",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot Word Clouds\n",
        "from wordcloud import WordCloud\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\n",
        "wordcloud1 = WordCloud( background_color='white',\n",
        "                        width=600,\n",
        "                        height=400).generate(\" \".join(positive_text_clean))\n",
        "ax1.imshow(wordcloud1)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('Positive text',fontsize=40);\n",
        "\n",
        "wordcloud2 = WordCloud( background_color='white',\n",
        "                        width=600,\n",
        "                        height=400).generate(\" \".join(negative_text_clean))\n",
        "ax2.imshow(wordcloud2)\n",
        "ax2.axis('off')\n",
        "ax2.set_title('Negative text',fontsize=40);\n",
        "\n",
        "wordcloud3 = WordCloud( background_color='white',\n",
        "                        width=600,\n",
        "                        height=400).generate(\" \".join(neutral_text_clean))\n",
        "ax3.imshow(wordcloud3)\n",
        "ax3.axis('off')\n",
        "ax3.set_title('Neutral text',fontsize=40);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho6qQLOmzy7-",
        "colab_type": "text"
      },
      "source": [
        "# DATA PREP\n",
        "\n",
        "Split into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEEY7JDVBRrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnE_Tgqlcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop selected_text column from the validation dataset (it will be added back once we are comparing it to our predictions)\n",
        "val_df_new = val_df.drop('selected_text', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8FMKmbQF7au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape)\n",
        "print(val_df_new.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBON4Ni8GSpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.array(train_df)\n",
        "val = np.array(val_df_new)\n",
        "test = np.array(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFB0LNoZ9C-1",
        "colab_type": "text"
      },
      "source": [
        "### Initiate the SimpleTransformers Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBRBDPcT7oTQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The SimpleTransformers library supports numerous tasks:  \n",
        "\n",
        "\n",
        "- Sequence Classification\n",
        "- Token Classification (NER)\n",
        "- Question Answering\n",
        "- Language Model Fine-Tuning\n",
        "- Language Model Training\n",
        "- Language Generation\n",
        "- T5 Model\n",
        "- Seq2Seq Tasks\n",
        "- Multi-Modal Classification\n",
        "- Conversational AI\n",
        "\n",
        "In this case, we are performing a <ins>Question Answering</ins> task.\n",
        "\n",
        "Supported model types:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln6FNmWRJlJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Question Answering model\n",
        "from simpletransformers.question_answering import QuestionAnsweringModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0y9mIBG8ax2",
        "colab_type": "text"
      },
      "source": [
        "### Format the data under the SimpleTransformer's *Question&Answer* schema "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfvz-pl1a4u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "To input the dataset, we need to assign each column to specific inputs\n",
        "- Context: The entire tweet\n",
        "- Question: The sentiment (positive, negative or neutral). In other words, we are asking *\\\"What part of the entire tweet best represents this sentiment?\\\"*\n",
        "- Answer: the label - the extracted text\n",
        "\n",
        "The formated data is assigned to the variables *qa_train, qa_val* and *qa_test* respectively\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvWbeYDGPT-P",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create list for training\n",
        "\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def find_all(input_str, search_str):\n",
        "    l1 = []\n",
        "    length = len(input_str)\n",
        "    index = 0\n",
        "    while index < length:\n",
        "        i = input_str.find(search_str, index)\n",
        "        if i == -1:\n",
        "            return l1\n",
        "        l1.append(i)\n",
        "        index = i + 1\n",
        "    return l1\n",
        "\n",
        "def do_qa_train(train):\n",
        "\n",
        "    output = []\n",
        "    for line in train:\n",
        "        context = line[1]\n",
        "\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        answers = []\n",
        "        answer = line[2]\n",
        "        if type(answer) != str or type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answer_starts = find_all(context, answer)\n",
        "        for answer_start in answer_starts:\n",
        "            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n",
        "            break\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "        \n",
        "    return output\n",
        "\n",
        "qa_train = do_qa_train(train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHc_N5JwzLmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qa_train[1:3]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD6Jk6WXHHx0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create val list\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def do_qa_val(val):\n",
        "    output = []\n",
        "    for line in val:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_val = do_qa_val(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nUa3ClTU3t",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create test list\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def do_qa_test(test):\n",
        "    output = []\n",
        "    for line in test:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_test = do_qa_test(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRWTSznadATJ",
        "colab_type": "text"
      },
      "source": [
        "### Create a Logging Module --> More info [here](https://realpython.com/python-logging/#:~:text=The%20Logging%20Module,-The%20logging%20module&text=It%20is%20used%20by%20most,homogeneous%20log%20for%20your%20application.&text=With%20the%20logging%20module%20imported,that%20you%20want%20to%20see.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-U5uNc3l5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Logs provide developers with an extra set of eyes that are constantly looking at the flow that an application is going through. They can store information, like which user or IP accessed the application.  \n",
        "\n",
        "With the logging module imported, you can use something called a “logger” to log messages that you want to see. By default, there are 5 standard levels indicating the severity of events.\n",
        "- DEBUG\n",
        "- INFO\n",
        "- WARNING\n",
        "- ERROR\n",
        "- CRITICAL\n",
        "\n",
        "In this case, we picked INFO and WARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBZQmX_2c-as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipp8nNzF8lMT",
        "colab_type": "text"
      },
      "source": [
        "### Follow the section that best applies to your case\n",
        "Load and Evaluate a Richardson's Pre-Trained Model (OPTION 1) \n",
        "\n",
        "**<ins>OR</ins>**\n",
        "\n",
        "Load, Train and Evaluate a SimpleTransformers' Model (OPTION 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDE_EE42bEW1",
        "colab_type": "text"
      },
      "source": [
        "# OPTION 1: Load and Evaluate a Richardson's Pre-Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HBfvRdPmnAS",
        "colab_type": "text"
      },
      "source": [
        "This model is available in the shared folder, under *models*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pHXf7bq9Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ROOT= '/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/models'\n",
        "FOLDER_NAME= 'richardson_distilbert-base-uncased-distilled-squad_A'\n",
        "\n",
        "FULL_PATH = join(ROOT, FOLDER_NAME)\n",
        "\n",
        "#Change the workspace to the model folder\n",
        "%cd '{FULL_PATH}' \n",
        "\n",
        "#Load the model's arguments list (required to setup the existing model) \n",
        "with open('args_train.json') as json_file: \n",
        "    train_args = json.load(json_file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiDki8xbA4ZY",
        "colab_type": "text"
      },
      "source": [
        "## Setup and load model\n",
        "\n",
        "Supported model types for Question&Answering:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet\n",
        "\n",
        "#### Details of the model we will load\n",
        "\n",
        "Model Architecture: [Distilbert](https://arxiv.org/abs/1910.01108), A faster and powerful version of BERT\n",
        "\n",
        "Shortcut Name: distilbert-base-uncased-distilled-squad\n",
        "\n",
        "Trained on: [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/), Standford Question Answering Dataset\n",
        "\n",
        "\n",
        "\n",
        "Additional architectures and shortcut names [here](https://huggingface.co/transformers/pretrained_models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CvvJBzas1GO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enter model architecture name\n",
        "MODEL_ARCHITECTURE='distilbert'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaLA-2ibEBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the model\n",
        "loaded_model = QuestionAnsweringModel(MODEL_ARCHITECTURE, 'outputs/', args=train_args, use_cuda=use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOWk-YAeKw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict the evaluation and test sets\n",
        "predictions_val = loaded_model.predict(qa_val)\n",
        "predictions_test = loaded_model.predict(qa_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7nwlVvmDwTz",
        "colab_type": "text"
      },
      "source": [
        "Let's check the structure of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grjM32X9DsOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It displays truncated long texts\n",
        "pd.set_option('display.max_colwidth',100)\n",
        "\n",
        "#Each ID contains multiple predicted extractions and their corresponding probabilities (prediction with highest probability is first)\n",
        "pd.DataFrame.from_dict(predictions_val)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Br61gyqD1RR",
        "colab_type": "text"
      },
      "source": [
        "Below commands will select the extracted text with the highest likelyhood (first item), as well as its corresponding probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvqhWsD_y_5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Validation set\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyy2j3ebEk0z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Test set\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnPM7OF9eQAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a copy of the validation and test sets so that we are not modifying the original sets\n",
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OOmUWMfeaSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the predicted result to the copied data frames \n",
        "sub_val_df['predicted_selected_text'] = text2_val[0].values\n",
        "sub_test_df['predicted_selected_text'] = text2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XQQx5QyizFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the probability of the prediction\n",
        "sub_val_df['prob'] = prop2_val[0].values\n",
        "sub_test_df['prob'] = prop2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FezYWVticSPX",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate Validation Test with Jaccard Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZP2Xsa1TS6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_val_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFR1TfTCPED0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make a copy of the original validation set and reset indexes\n",
        "df_js=sub_val_df.copy()\n",
        "df_js=df_js.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnubVC19Hl7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the Jaccard Score function\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeNcF7WxM52h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Obtain JS for the entire set\n",
        "results = []\n",
        "for i in range(len(df_js)):\n",
        "    score = jaccard(df_js['selected_text'].iloc[i], df_js['predicted_selected_text'].iloc[i])\n",
        "    results.append(score)\n",
        "    \n",
        "Jaccard_score = sum(results) / len(results)\n",
        "Jaccard_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-A7RQ9kWj4S",
        "colab_type": "text"
      },
      "source": [
        "## Prepare and Submit Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqGszrvAFQZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP4AneeAICFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare file for submission\n",
        "final_test=sub_test_df[['textID','predicted_selected_text']]\n",
        "final_test.columns=['textID','selected_text']\n",
        "final_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu8C-zphp9DP",
        "colab_type": "text"
      },
      "source": [
        "# OPTION 2: Load, train and evaluate a SimpleTransformers' Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyGcwEoKJE-V",
        "colab_type": "text"
      },
      "source": [
        "Create a folder that will contain the new model's PyTorch and hyperameters files. Follow below instructions to assign a name to the *'NAME_OF_MODEL'*  folder:\n",
        "\n",
        "\n",
        ">>**Basic Structure:**\n",
        "\n",
        ">>Name_Model_Version  \n",
        "\n",
        ">>>Where:\n",
        "- Name: Your name\n",
        "- Model: Based on the model names used in the official Transformers site: https://huggingface.co/transformers/pretrained_models.html\n",
        "- Version: For notebooks with same name and model but different hyperparameters, include the version (A, B, C...)\n",
        "  \n",
        "  >>>Examples:\n",
        "  - Lucas_distilroberta-base_A\n",
        "  - Lucas_distilroberta-base_B\n",
        "  - Landis_bert_A  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTC_2IcRKmH4",
        "colab_type": "text"
      },
      "source": [
        "Supported model types for Question&Answering:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SEWvIvVgvMr",
        "colab_type": "text"
      },
      "source": [
        "Under Colab Notebook, below command will create a *my-tweet-folder* directory and then a *model* folder inside of it (this is where all your models will be stored)\n",
        "\n",
        "**Skip it if you have done this already**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMxQjzU4g31A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd '/gdrive/My Drive/Colab Notebooks'\n",
        "%mkdir 'my-tweet-folder' \n",
        "%cd '/gdrive/My Drive/Colab Notebooks/my-tweet-folder'\n",
        "%mkdir 'models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaUrF49NHrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change this BEFORE RUNNING *********************************************************************************************\n",
        "YOUR_NAME = 'richardson'\n",
        "YOUR_LETTER = 'A'     # identify your model A,B,C,D,E...\n",
        "MODEL_ARCHITECTURE = 'distilbert'\n",
        "MODEL_NAME = 'distilbert-base-uncased-distilled-squad'\n",
        "# ************************************************************************************************************************\n",
        "\n",
        "#Don't change below lines:\n",
        "FULL_NAME = YOUR_NAME + '_' + MODEL_NAME + '_' + YOUR_LETTER \n",
        "\n",
        "\n",
        "ROOT = '/gdrive/My Drive/Colab Notebooks/my-tweet-folder/models' \n",
        "FULL_PATH = join(ROOT, FULL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWhNRnXl4ndR",
        "colab_type": "text"
      },
      "source": [
        "Below command will create a folder where all the model's files will be stored"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEXL0IrcGNrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Change directory to \"my-tweet-folder/models\"\n",
        "%cd '{ROOT}'\n",
        "#It creates the folder where the model components will be saved. If you have a folder with the same name, it will give you an error\n",
        "%mkdir '{FULL_NAME}' \n",
        "#Change the workspace to the recently created folder\n",
        "%cd '{FULL_PATH}' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlWY8Y7MYSmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For more arguments, refer to this link --> https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model\n",
        "\n",
        "args_train={'reprocess_input_data': True,\n",
        "'overwrite_output_dir': True,\n",
        "'learning_rate': 5e-5,\n",
        "'num_train_epochs': 1,\n",
        "'max_seq_length': 192,\n",
        "'doc_stride': 64,\n",
        "'fp16': False,\n",
        "}\n",
        "\n",
        "#Fit the model\n",
        "model = QuestionAnsweringModel(MODEL_ARCHITECTURE, MODEL_NAME, args=args_train, use_cuda=use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XifqXffjlGqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This line creates a JSON file that is required to load the model in the future\n",
        "with open('args_train.json', 'w') as fp: \n",
        "    json.dump(args_train, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdo6wnSdYJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the model\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "model.train_model(qa_train)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttTEa5vskmCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict the evaluation and test sets\n",
        "predictions_val = model.predict(qa_val)\n",
        "predictions_test = model.predict(qa_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m2Salb4ESlv",
        "colab_type": "text"
      },
      "source": [
        "Let's check the structure of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbpJVai3_q1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It displays truncated long texts\n",
        "pd.set_option('display.max_colwidth',100)\n",
        "\n",
        "#Each ID contains multiple predicted extractions and their corresponding probabilities (prediction with highest probability is first)\n",
        "pd.DataFrame.from_dict(predictions_val)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk5gdYHKEMoO",
        "colab_type": "text"
      },
      "source": [
        "Below commands will select the extracted text with the highest likelyhood (first item), as well as its corresponding probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_ZrfqQNkHA",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Validation set\n",
        "\n",
        "#Validation Set highest probability output\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6btRf0y4bQZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Test set\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1NXIUmhU64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a copy of the validation and test sets so that we are not modifying the original sets\n",
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUB5FeXMhXbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the predicted result to the copied data frames \n",
        "sub_val_df['predicted_selected_text'] = text2_val[0].values\n",
        "sub_test_df['predicted_selected_text'] = text2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CChz6l_gsVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the probability of the prediction\n",
        "sub_val_df['prob'] = prop2_val[0].values\n",
        "sub_test_df['prob'] = prop2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5-MTkiYlXwTM"
      },
      "source": [
        "## Evaluate Validation Test with Jaccard Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ze65OsAnXwTX",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_val_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FHaafsM0XwTy",
        "colab": {}
      },
      "source": [
        "#Make a copy of the original validation set and reset indexes\n",
        "df_js=sub_val_df.copy()\n",
        "df_js=df_js.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMOOGs_kXwT8",
        "colab": {}
      },
      "source": [
        "#Define the Jaccard Score function\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-1h7sfJXwUD",
        "colab": {}
      },
      "source": [
        "#Obtain JS for the entire set\n",
        "results = []\n",
        "for i in range(len(df_js)):\n",
        "    score = jaccard(df_js['selected_text'].iloc[i], df_js['predicted_selected_text'].iloc[i])\n",
        "    results.append(score)\n",
        "    \n",
        "Jaccard_score = sum(results) / len(results)\n",
        "Jaccard_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l9eqx6aCYQVa"
      },
      "source": [
        "## Prepare and Submit Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6puQFRR0YQVl",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ZY9Ep8cYQV4",
        "colab": {}
      },
      "source": [
        "#Prepare file for submission\n",
        "final_test=sub_test_df[['textID','predicted_selected_text']]\n",
        "final_test.columns=['textID','selected_text']\n",
        "final_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5S0VD3neYQWH",
        "colab": {}
      },
      "source": [
        "#Submit\n",
        "final_test[['textID','selected_text']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission successful\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne55UzM9DppA",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model arguments and other files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xf74QuHkYQWT",
        "colab": {}
      },
      "source": [
        "#Additonal files if required\n",
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}