{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_SingleM_Template",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a3e129d6eb248a6823e72539b5ee466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d382d37012cf4183be6b202123bd35aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b588677085048068a4b0ceda4246c1f",
              "IPY_MODEL_b3b609f7579d4ba1a0d099819672460c"
            ]
          }
        },
        "d382d37012cf4183be6b202123bd35aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b588677085048068a4b0ceda4246c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f7a7412383a9482c8316beb4a04bcfcc",
            "_dom_classes": [],
            "description": "Epoch:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f12f19ae98a48cd9bc346b04265a05f"
          }
        },
        "b3b609f7579d4ba1a0d099819672460c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e91b4560b4ad4b669818b16e679d541f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e92d3cf38db4916bba272d063135f69"
          }
        },
        "f7a7412383a9482c8316beb4a04bcfcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f12f19ae98a48cd9bc346b04265a05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e91b4560b4ad4b669818b16e679d541f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e92d3cf38db4916bba272d063135f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "884249c3a06b4692890d2503cef275d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5820bacbe6b0457f8949764ec6fc10b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_849ae23e92dd4333bcc98594aaaf6f1f",
              "IPY_MODEL_9fe02fbbcda84173b15815bc609baf2c"
            ]
          }
        },
        "5820bacbe6b0457f8949764ec6fc10b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "849ae23e92dd4333bcc98594aaaf6f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d4a24f86c1147979b6f751538a814e8",
            "_dom_classes": [],
            "description": "Current iteration:  54%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2748,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1484,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22032a87de21489a85637c6f182ffd58"
          }
        },
        "9fe02fbbcda84173b15815bc609baf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98c3c610dd6d4c9ba2115e5f99cb81ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1484/2748 [02:27&lt;02:05, 10.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20399765152746ff94a47a7697172e8c"
          }
        },
        "9d4a24f86c1147979b6f751538a814e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22032a87de21489a85637c6f182ffd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98c3c610dd6d4c9ba2115e5f99cb81ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20399765152746ff94a47a7697172e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DianaMoyano1/NLP-Sentiment_Extraction_Challenge/blob/master/Tutorial/Tutorial_SingleM_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGR6ljGnRWL",
        "colab_type": "text"
      },
      "source": [
        "# SETUP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnOkICFeQxsY",
        "colab_type": "text"
      },
      "source": [
        "1. Click on Runtime --> Change runtime type\n",
        "2. Select **GPU** under *Hardware accelerator*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94gEgYzgV72",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Before running this notebook, make sure you have added the *'tweet-sentiment-extraction-tutorial'* shortcut to your Gdrive, inside the *'Colab Notebooks'* directory\n",
        "\n",
        "![](https://serving.photos.photobox.com/817973499a3406a94b0556385350836dda810c16c1a20967bd25b50dd6e367b3dcb1e30b.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPBTI365dJLo",
        "colab_type": "text"
      },
      "source": [
        "### Mount Your Own Gdrive\n",
        "\n",
        "Below command will require you to validate your account, and it will provide you with a temporary access code to paste in the field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-bkv7WRK7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount your local Google drive and show the models you have\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls '/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/models' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SclTK2sEy2U",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#install the following packages. The --quiet command will reduce the output lines\n",
        "!pip install transformers==2.11.0 --quiet\n",
        "!pip install tensorflow==2.2.0 --quiet\n",
        "!pip install tensorboardX --quiet\n",
        "!pip install simpletransformers --quiet\n",
        "\n",
        "\n",
        "!pip install scattertext --quiet \n",
        "!pip install plotly --quiet\n",
        "!pip install dash --quiet\n",
        "!pip install wordcloud --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-f6h_O-ax7b",
        "colab_type": "text"
      },
      "source": [
        "### Setup NVIDIA APEX\n",
        "\n",
        "Tool to enable mixed precision training in Pytorch (the underlying structure for SimpleTransformers). More info here: https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EKbT79HZ1FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile setup.sh\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8BU4o8aAxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will take 7-10 mins to run\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "!sh setup.sh --quiet\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sonPGlnWahCx",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6XzV6-3RTGe",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#Import packages\n",
        "from os.path import join\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from apex import amp\n",
        "import json\n",
        "\n",
        "\n",
        "use_cuda = True ##If True, GPU will be used"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7T-lNV39yOJ",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1aa6YfTGJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/train.csv')\n",
        "test_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS794cV0XDL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQpFNQnWXFqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho6qQLOmzy7-",
        "colab_type": "text"
      },
      "source": [
        "# DATA PREP\n",
        "\n",
        "Split into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEEY7JDVBRrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnE_Tgqlcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop selected_text column from the validation dataset (it will be added back once we are comparing it to our predictions)\n",
        "val_df_new = val_df.drop('selected_text', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8FMKmbQF7au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape)\n",
        "print(val_df_new.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBON4Ni8GSpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.array(train_df)\n",
        "val = np.array(val_df_new)\n",
        "test = np.array(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFB0LNoZ9C-1",
        "colab_type": "text"
      },
      "source": [
        "### Initiate the SimpleTransformers Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBRBDPcT7oTQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The SimpleTransformers library supports numerous tasks:  \n",
        "\n",
        "\n",
        "- Sequence Classification\n",
        "- Token Classification (NER)\n",
        "- Question Answering\n",
        "- Language Model Fine-Tuning\n",
        "- Language Model Training\n",
        "- Language Generation\n",
        "- T5 Model\n",
        "- Seq2Seq Tasks\n",
        "- Multi-Modal Classification\n",
        "- Conversational AI\n",
        "\n",
        "In this case, we are performing a <ins>Question Answering</ins> task.\n",
        "\n",
        "Supported model types:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln6FNmWRJlJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Question Answering model\n",
        "from simpletransformers.question_answering import QuestionAnsweringModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0y9mIBG8ax2",
        "colab_type": "text"
      },
      "source": [
        "### Format the data under the SimpleTransformer's *Question&Answer* schema "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfvz-pl1a4u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "To input the dataset, we need to assign each column to specific inputs\n",
        "- Context: The entire tweet\n",
        "- Question: The sentiment (positive, negative or neutral). In other words, we are asking *\\\"What part of the entire tweet best represents this sentiment?\\\"*\n",
        "- Answer: the label - the extracted text\n",
        "\n",
        "The formated data is assigned to the variables *qa_train, qa_val* and *qa_test* respectively\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvWbeYDGPT-P",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create list for training\n",
        "\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def find_all(input_str, search_str):\n",
        "    l1 = []\n",
        "    length = len(input_str)\n",
        "    index = 0\n",
        "    while index < length:\n",
        "        i = input_str.find(search_str, index)\n",
        "        if i == -1:\n",
        "            return l1\n",
        "        l1.append(i)\n",
        "        index = i + 1\n",
        "    return l1\n",
        "\n",
        "def do_qa_train(train):\n",
        "\n",
        "    output = []\n",
        "    for line in train:\n",
        "        context = line[1]\n",
        "\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        answers = []\n",
        "        answer = line[2]\n",
        "        if type(answer) != str or type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answer_starts = find_all(context, answer)\n",
        "        for answer_start in answer_starts:\n",
        "            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n",
        "            break\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "        \n",
        "    return output\n",
        "\n",
        "qa_train = do_qa_train(train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHc_N5JwzLmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qa_train[1:3]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD6Jk6WXHHx0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create val list\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def do_qa_val(val):\n",
        "    output = []\n",
        "    for line in val:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_val = do_qa_val(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nUa3ClTU3t",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create test list\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def do_qa_test(test):\n",
        "    output = []\n",
        "    for line in test:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_test = do_qa_test(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRWTSznadATJ",
        "colab_type": "text"
      },
      "source": [
        "### Create a Logging Module --> More info [here](https://realpython.com/python-logging/#:~:text=The%20Logging%20Module,-The%20logging%20module&text=It%20is%20used%20by%20most,homogeneous%20log%20for%20your%20application.&text=With%20the%20logging%20module%20imported,that%20you%20want%20to%20see.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-U5uNc3l5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Logs provide developers with an extra set of eyes that are constantly looking at the flow that an application is going through. They can store information, like which user or IP accessed the application.  \n",
        "\n",
        "With the logging module imported, you can use something called a “logger” to log messages that you want to see. By default, there are 5 standard levels indicating the severity of events.\n",
        "- DEBUG\n",
        "- INFO\n",
        "- WARNING\n",
        "- ERROR\n",
        "- CRITICAL\n",
        "\n",
        "In this case, we picked INFO and WARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBZQmX_2c-as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipp8nNzF8lMT",
        "colab_type": "text"
      },
      "source": [
        "### Load, Train and Evaluate a SimpleTransformers' Pre-Trained Model **<ins>OR</ins>** Load and Evaluate a Richardson's Pre-Trained Model  \n",
        "\n",
        "Follow the section that best applies to your case.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu8C-zphp9DP",
        "colab_type": "text"
      },
      "source": [
        "# OPTION 1: Load, train and evaluate a SimpleTransformers' Pre-trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyGcwEoKJE-V",
        "colab_type": "text"
      },
      "source": [
        "Create a folder that will contain the new model's PyTorch and hyperameters files. Follow below instructions to assign a name to the *'NAME_OF_MODEL'*  folder:\n",
        "\n",
        "\n",
        ">>**Basic Structure:**\n",
        "\n",
        ">>Name_Model_Version  \n",
        "\n",
        ">>>Where:\n",
        "- Name: Your name\n",
        "- Model: Based on the model names used in the official Transformers site: https://huggingface.co/transformers/pretrained_models.html\n",
        "- Version: For notebooks with same name and model but different hyperparameters, include the version (A, B, C...)\n",
        "  \n",
        "  >>>Examples:\n",
        "  - Lucas_distilroberta-base_A\n",
        "  - Lucas_distilroberta-base_B\n",
        "  - Landis_bert_A  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTC_2IcRKmH4",
        "colab_type": "text"
      },
      "source": [
        "Supported model types for Question&Answering:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaUrF49NHrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change this BEFORE RUNNING *********************************************************************************************\n",
        "YOUR_NAME = 'test'\n",
        "YOUR_LETTER = 'B'     # identify your model A,B,C,D,E...\n",
        "MODEL_ARCHITECTURE = 'distilbert'\n",
        "MODEL_NAME = 'distilbert-base-uncased-distilled-squad'\n",
        "# ************************************************************************************************************************\n",
        "\n",
        "#Don't change below lines:\n",
        "FULL_NAME = YOUR_NAME + '_' + MODEL_NAME + '_' + YOUR_LETTER \n",
        "\n",
        "\n",
        "ROOT = '/gdrive/My Drive/Colab Notebooks/my-folder/models' \n",
        "FULL_PATH = join(ROOT, FULL_NAME)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWhNRnXl4ndR",
        "colab_type": "text"
      },
      "source": [
        "Below command will create a folder where all the model's files will be stored"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEXL0IrcGNrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "19553be5-4e7b-4721-c314-00bc3b63df43"
      },
      "source": [
        "#Change directory to \"tweet-sentiment-extraction-tutorial/models\"\n",
        "%cd '{ROOT}'\n",
        "#It creates the folder where the model components will be saved. If you have a folder with the same name, it will give you an error\n",
        "%mkdir '{FULL_NAME}' \n",
        "#Change the workspace to the recently created folder\n",
        "%cd '{FULL_PATH}' "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab Notebooks/my-folder/models\n",
            "[Errno 2] No such file or directory: '/gdrive/My Drive/Colab Notebooks/my-folder/models/test_distilbert-base-uncased-distilled-squad_B'\n",
            "/gdrive/My Drive/Colab Notebooks/my-folder/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlWY8Y7MYSmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For more arguments, refer to this link --> https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model\n",
        "\n",
        "args_train={'reprocess_input_data': True,\n",
        "'overwrite_output_dir': True,\n",
        "'learning_rate': 5e-5,\n",
        "'num_train_epochs': 1,\n",
        "'max_seq_length': 192,\n",
        "'doc_stride': 64,\n",
        "'fp16': False,\n",
        "}\n",
        "\n",
        "#Fit the model\n",
        "model = QuestionAnsweringModel(MODEL_ARCHITECTURE, MODEL_NAME, args=args_train, use_cuda=use_cuda)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdo6wnSdYJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "7a3e129d6eb248a6823e72539b5ee466",
            "d382d37012cf4183be6b202123bd35aa",
            "7b588677085048068a4b0ceda4246c1f",
            "b3b609f7579d4ba1a0d099819672460c",
            "f7a7412383a9482c8316beb4a04bcfcc",
            "1f12f19ae98a48cd9bc346b04265a05f",
            "e91b4560b4ad4b669818b16e679d541f",
            "6e92d3cf38db4916bba272d063135f69",
            "884249c3a06b4692890d2503cef275d8",
            "5820bacbe6b0457f8949764ec6fc10b8",
            "849ae23e92dd4333bcc98594aaaf6f1f",
            "9fe02fbbcda84173b15815bc609baf2c",
            "9d4a24f86c1147979b6f751538a814e8",
            "22032a87de21489a85637c6f182ffd58",
            "98c3c610dd6d4c9ba2115e5f99cb81ba",
            "20399765152746ff94a47a7697172e8c"
          ]
        },
        "outputId": "1c08e4df-dc6c-46eb-fdcc-cd8bd975fa7a"
      },
      "source": [
        "#Train the model\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "model.train_model(qa_train)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
            "convert squad examples to features: 100%|██████████| 21983/21983 [00:19<00:00, 1126.36it/s]\n",
            "add example index and unique id: 100%|██████████| 21983/21983 [00:00<00:00, 801524.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a3e129d6eb248a6823e72539b5ee466",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "884249c3a06b4692890d2503cef275d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=2748.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running loss: 2.037285"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running loss: 0.314654"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttTEa5vskmCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict the evaluation and test sets\n",
        "predictions_val = model.predict(qa_val)\n",
        "predictions_test = model.predict(qa_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m2Salb4ESlv",
        "colab_type": "text"
      },
      "source": [
        "Let's check the structure of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbpJVai3_q1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It displays truncated long texts\n",
        "pd.set_option('display.max_colwidth',100)\n",
        "\n",
        "#Each ID contains multiple predicted extractions and their corresponding probabilities (prediction with highest probability is first)\n",
        "pd.DataFrame.from_dict(predictions_val)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk5gdYHKEMoO",
        "colab_type": "text"
      },
      "source": [
        "Below commands will select the extracted text with the highest likelyhood (first item), as well as its corresponding probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_ZrfqQNkHA",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Validation set\n",
        "\n",
        "#Validation Set highest probability output\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6btRf0y4bQZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Test set\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1NXIUmhU64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a copy of the validation and test sets so that we are not modifying the original sets\n",
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUB5FeXMhXbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the predicted result to the copied data frames \n",
        "sub_val_df['predicted_selected_text'] = text2_val[0].values\n",
        "sub_test_df['predicted_selected_text'] = text2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CChz6l_gsVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the probability of the prediction\n",
        "sub_val_df['prob'] = prop2_val[0].values\n",
        "sub_test_df['prob'] = prop2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5-MTkiYlXwTM"
      },
      "source": [
        "## Evaluate Validation Test with Jaccard Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ze65OsAnXwTX",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_val_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FHaafsM0XwTy",
        "colab": {}
      },
      "source": [
        "#Make a copy of the original validation set and reset indexes\n",
        "df_js=sub_val_df.copy()\n",
        "df_js=df_js.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMOOGs_kXwT8",
        "colab": {}
      },
      "source": [
        "#Define the Jaccard Score function\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-1h7sfJXwUD",
        "colab": {}
      },
      "source": [
        "#Obtain JS for the entire set\n",
        "results = []\n",
        "for i in range(len(df_js)):\n",
        "    score = jaccard(df_js['selected_text'].iloc[i], df_js['predicted_selected_text'].iloc[i])\n",
        "    results.append(score)\n",
        "    \n",
        "Jaccard_score = sum(results) / len(results)\n",
        "Jaccard_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l9eqx6aCYQVa"
      },
      "source": [
        "## Prepare and Submit Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6puQFRR0YQVl",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ZY9Ep8cYQV4",
        "colab": {}
      },
      "source": [
        "#Prepare file for submission\n",
        "final_test=sub_test_df[['textID','predicted_selected_text']]\n",
        "final_test.columns=['textID','selected_text']\n",
        "final_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5S0VD3neYQWH",
        "colab": {}
      },
      "source": [
        "#Submit\n",
        "final_test[['textID','selected_text']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission successful\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne55UzM9DppA",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model arguments and other files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XifqXffjlGqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This line creates a JSON file that is required to load the model in the future\n",
        "with open('args_train.json', 'w') as fp: \n",
        "    json.dump(args_train, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xf74QuHkYQWT",
        "colab": {}
      },
      "source": [
        "#Additonal files if required\n",
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDE_EE42bEW1",
        "colab_type": "text"
      },
      "source": [
        "# OPTION 2: Load and Evaluate a Richardson's Pre-Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ejl-mZ0-GTJ",
        "colab_type": "text"
      },
      "source": [
        "#### Distilbert --> A faster yet powerful version of BERT\n",
        "https://arxiv.org/abs/1910.01108\n",
        "\n",
        "#### SQuAD --> Standford Question Answering Dataset\n",
        "https://rajpurkar.github.io/SQuAD-explorer/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pHXf7bq9Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ROOT= '/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction-tutorial/models'\n",
        "FOLDER_NAME= 'richardson_distilbert-base-uncased-distilled-squad_A'\n",
        "\n",
        "FULL_PATH = join(ROOT, FOLDER_NAME)\n",
        "\n",
        "#Change the workspace to the model folder\n",
        "%cd '{FULL_PATH}' \n",
        "\n",
        "#Load the model's arguments list (required to setup the existing model) \n",
        "with open('args_train.json') as json_file: \n",
        "    train_args = json.load(json_file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiDki8xbA4ZY",
        "colab_type": "text"
      },
      "source": [
        "## Setup loaded model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaLA-2ibEBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the model\n",
        "loaded_model = QuestionAnsweringModel(MODEL_ARCHITECTURE, 'outputs/', args=train_args, use_cuda=use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOWk-YAeKw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict the evaluation and test sets\n",
        "predictions_val = loaded_model.predict(qa_val)\n",
        "predictions_test = loaded_model.predict(qa_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7nwlVvmDwTz",
        "colab_type": "text"
      },
      "source": [
        "Let's check the structure of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grjM32X9DsOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It displays truncated long texts\n",
        "pd.set_option('display.max_colwidth',100)\n",
        "\n",
        "#Each ID contains multiple predicted extractions and their corresponding probabilities (prediction with highest probability is first)\n",
        "pd.DataFrame.from_dict(predictions_val)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Br61gyqD1RR",
        "colab_type": "text"
      },
      "source": [
        "Below commands will select the extracted text with the highest likelyhood (first item), as well as its corresponding probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvqhWsD_y_5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Validation set\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyy2j3ebEk0z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Obtain output with the highest prob - Test set\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnPM7OF9eQAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a copy of the validation and test sets so that we are not modifying the original sets\n",
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OOmUWMfeaSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the predicted result to the copied data frames \n",
        "sub_val_df['predicted_selected_text'] = text2_val[0].values\n",
        "sub_test_df['predicted_selected_text'] = text2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XQQx5QyizFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add the probability of the prediction\n",
        "sub_val_df['prob'] = prop2_val[0].values\n",
        "sub_test_df['prob'] = prop2_test[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FezYWVticSPX",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate Validation Test with Jaccard Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZP2Xsa1TS6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_val_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFR1TfTCPED0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make a copy of the original validation set and reset indexes\n",
        "df_js=sub_val_df.copy()\n",
        "df_js=df_js.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnubVC19Hl7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the Jaccard Score function\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeNcF7WxM52h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Obtain JS for the entire set\n",
        "results = []\n",
        "for i in range(len(df_js)):\n",
        "    score = jaccard(df_js['selected_text'].iloc[i], df_js['predicted_selected_text'].iloc[i])\n",
        "    results.append(score)\n",
        "    \n",
        "Jaccard_score = sum(results) / len(results)\n",
        "Jaccard_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-A7RQ9kWj4S",
        "colab_type": "text"
      },
      "source": [
        "## Prepare and Submit Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqGszrvAFQZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check head of dataset\n",
        "sub_test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP4AneeAICFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare file for submission\n",
        "final_test=sub_test_df[['textID','predicted_selected_text']]\n",
        "final_test.columns=['textID','selected_text']\n",
        "final_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFqPciC4QKbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Submit\n",
        "final_test[['textID','selected_text']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission successful\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh0IHQsMIRwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Additonal files if required\n",
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}