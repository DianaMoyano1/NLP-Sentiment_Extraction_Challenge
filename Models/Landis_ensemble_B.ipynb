{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  NLP QA Kaggle distilbert Cases.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DianaMoyano1/NLP-Sentiment_Extraction_Challenge/blob/master/Workstream_1/Landis_ensemble_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGR6ljGnRWL",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 1: Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SclTK2sEy2U",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#install the following first\n",
        "!pip install transformers==2.11.0 --quiet\n",
        "!pip install tensorflow==2.2.0 --quiet\n",
        "!pip install tensorboardX --quiet\n",
        "!pip install simpletransformers --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-f6h_O-ax7b",
        "colab_type": "text"
      },
      "source": [
        "### Setup NVIDIA APEX\n",
        "\n",
        "Tool to enable mixed precision training. More info here: https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EKbT79HZ1FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile setup.sh\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8BU4o8aAxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will take 10mins to run\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "!sh setup.sh --quiet\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sonPGlnWahCx",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6XzV6-3RTGe",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#Import packages\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from apex import amp\n",
        "from glob import glob\n",
        "import os\n",
        "from random import random\n",
        "from pathlib import Path\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TFBertModel, BertModel, DistilBertModel, XLNetModel, RobertaModel\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from os.path import join\n",
        "\n",
        "\n",
        "use_cuda = True ##If True, GPU will be used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPBTI365dJLo",
        "colab_type": "text"
      },
      "source": [
        "### Mount Your Own Gdrive\n",
        "\n",
        "Below command will require you to validate your account, and it will provide you with a temporary access code to paste in the required field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-bkv7WRK7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7T-lNV39yOJ",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94gEgYzgV72",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Before running below command, make sure you have...\n",
        "- Created a *'tweet-sentiment-extraction'* folder inside the *'Colab Notebooks'* directory\n",
        "- Uploaded the *train.csv* and *test.csv* files to the *'tweet-sentiment-extraction'* folder \n",
        "\n",
        "Finally, make sure you have a folder called *'models'* inside the *'tweet-sentiment-extraction'* directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1aa6YfTGJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/train.csv')\n",
        "test_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/test.csv')\n",
        "\n",
        "\n",
        "\n",
        "#sub_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/sample_submission.csv') #Optional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho6qQLOmzy7-",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data\n",
        "\n",
        "Split into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEEY7JDVBRrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnE_Tgqlcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop selected_text column from the validation dataset (it will be later compared to the ground truth)\n",
        "val_df_new = val_df.drop('selected_text', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8FMKmbQF7au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape)\n",
        "print(val_df_new.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBON4Ni8GSpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.array(train_df)\n",
        "val = np.array(val_df_new)\n",
        "test = np.array(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFB0LNoZ9C-1",
        "colab_type": "text"
      },
      "source": [
        "### Initiate the SimpleTransformers Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln6FNmWRJlJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simpletransformers.question_answering import QuestionAnsweringModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DsYbQI18gP7",
        "colab_type": "text"
      },
      "source": [
        "### Create a Logging Module --> More info [here](https://realpython.com/python-logging/#:~:text=The%20Logging%20Module,-The%20logging%20module&text=It%20is%20used%20by%20most,homogeneous%20log%20for%20your%20application.&text=With%20the%20logging%20module%20imported,that%20you%20want%20to%20see.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7kc0kuO5oF4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Logs provide developers with an extra set of eyes that are constantly looking at the flow that an application is going through. They can store information, like which user or IP accessed the application.  \n",
        "\n",
        "With the logging module imported, you can use something called a “logger” to log messages that you want to see. By default, there are 5 standard levels indicating the severity of events.\n",
        "- DEBUG\n",
        "- INFO\n",
        "- WARNING\n",
        "- ERROR\n",
        "- CRITICAL\n",
        "\n",
        "In this case, we picked INFO and WARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-18PYUqo4yLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne55UzM9DppA",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model arguments and other files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ln-OCSbUtAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XifqXffjlGqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This line creates a JSON file that is required when loading the model\n",
        "with open('args_train.json', 'w') as fp: \n",
        "    json.dump(args_train, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDE_EE42bEW1",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 3: Load and Evaluate a Richardson's Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pHXf7bq9Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ROOT = '/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/models' #Don't change\n",
        "\n",
        "FULL_PATH = join(ROOT, NAME_OF_MODEL)\n",
        "\n",
        "#Change the workspace to the model folder\n",
        "%cd '{FULL_PATH}' \n",
        "\n",
        "#Load the model's arguments list (required to setup the existing model) \n",
        "with open('args_train.json') as json_file: \n",
        "    train_args = json.load(json_file) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiDki8xbA4ZY",
        "colab_type": "text"
      },
      "source": [
        "#### Setup loaded model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZCmZyVANve",
        "colab_type": "text"
      },
      "source": [
        "Supported model types for Question&Answering:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet\n",
        "\n",
        "Related link: https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaLA-2ibEBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = QuestionAnsweringModel('distilbert', 'outputs/checkpoint-2748-epoch-1', args=train_args, use_cuda=use_cuda)\n",
        "loaded_model2 = QuestionAnsweringModel('albert', 'outputs/checkpoint-2748-epoch-1', args=train_args, use_cuda=use_cuda)\n",
        "loaded_model3 = QuestionAnsweringModel('roberta', 'outputs/checkpoint-2748-epoch-1', args=train_args, use_cuda=use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOWk-YAeKw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val = model.predict(qa_val)\n",
        "predictions_test = model.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QY1pQVoTKa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val2 = model2.predict(qa_val)\n",
        "predictions_test2 = model2.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1m2Byd5TKOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val3 = model3.predict(qa_val)\n",
        "predictions_test3 = model3.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvqhWsD_y_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)\n",
        "#test\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnftsfJsbFlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val2 = pd.DataFrame.from_dict(predictions_val2)\n",
        "text_val2 = pd.DataFrame(predictions_val2[0])\n",
        "prob_val2 = pd.DataFrame(predictions_val2[1])\n",
        "prop1_val2 = prob_val2['probability'].tolist()\n",
        "prop2_val2 = pd.DataFrame(prop1_val2)\n",
        "text1_val2 = text_val2['answer'].tolist()\n",
        "text2_val2 = pd.DataFrame(text1_val2)\n",
        "#test\n",
        "predictions_df_test2 = pd.DataFrame.from_dict(predictions_test2)\n",
        "text_test2 = pd.DataFrame(predictions_test2[0])\n",
        "prob_test2 = pd.DataFrame(predictions_test2[1])\n",
        "prop1_test2 = prob_test2['probability'].tolist()\n",
        "prop2_test2 = pd.DataFrame(prop1_test2)\n",
        "text1_test2 = text_test2['answer'].tolist()\n",
        "text2_test2 = pd.DataFrame(text1_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYgWwk94bFdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val3 = pd.DataFrame.from_dict(predictions_val3)\n",
        "text_val3 = pd.DataFrame(predictions_val3[0])\n",
        "prob_val3 = pd.DataFrame(predictions_val3[1])\n",
        "prop1_val3 = prob_val3['probability'].tolist()\n",
        "prop2_val3 = pd.DataFrame(prop1_val3)\n",
        "text1_val3 = text_val3['answer'].tolist()\n",
        "text2_val3 = pd.DataFrame(text1_val3)\n",
        "#test\n",
        "predictions_df_test3 = pd.DataFrame.from_dict(predictions_test3)\n",
        "text_test3 = pd.DataFrame(predictions_test3[0])\n",
        "prob_test3 = pd.DataFrame(predictions_test3[1])\n",
        "prop1_test3 = prob_test3['probability'].tolist()\n",
        "prop2_test3 = pd.DataFrame(prop1_test3)\n",
        "text1_test3 = text_test3['answer'].tolist()\n",
        "text2_test3 = pd.DataFrame(text1_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnPM7OF9eQAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()\n",
        "sub_val_df2 = val_df.copy()\n",
        "sub_test_df2 = test_df.copy()\n",
        "sub_val_df3 = val_df.copy()\n",
        "sub_test_df3 = test_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HS_Rxvugnb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create files to export \n",
        "sub_val_df['selected_text_results'] = text2_val[0].values\n",
        "sub_test_df['selected_text_results'] = text2_test[0].values\n",
        "sub_val_df2['selected_text_results'] = text2_val2[0].values\n",
        "sub_test_df2['selected_text_results'] = text2_test2[0].values\n",
        "sub_val_df3['selected_text_results'] = text2_val3[0].values\n",
        "sub_test_df3['selected_text_results'] = text2_test3[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-rGNG_FeV_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OOmUWMfeaSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create files to export \n",
        "sub_val_df['selected_text_results'] = text2_val[0].values\n",
        "sub_test_df['selected_text_results'] = text2_test[0].values\n",
        "sub_val_df2['selected_text_results'] = text2_val2[0].values\n",
        "sub_test_df2['selected_text_results'] = text2_test2[0].values\n",
        "sub_val_df3['selected_text_results'] = text2_val3[0].values\n",
        "sub_test_df3['selected_text_results'] = text2_test3[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXKogfZ6icjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df = sub_val_df[['textID','selected_text','selected_text_results']]\n",
        "sub_val_df2 = sub_val_df2[['textID','selected_text','selected_text_results']]\n",
        "sub_val_df3 = sub_val_df3[['textID','selected_text','selected_text_results']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ym84Sj5iz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = sub_val_df.merge(sub_val_df2,on=['textID','selected_text'],how='left')\n",
        "final = final.merge(sub_val_df3,on=['textID','selected_text'],how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNRrHZy4jDJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vLGSElwd3HE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh0IHQsMIRwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSDYPad472ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def votes_and_select(str1,str2,str3):\n",
        "  try:\n",
        "    #print(str1,str2,str3)\n",
        "    s1_list = str1.split()\n",
        "    s2_list = str2.split()\n",
        "    s3_list = str3.split()\n",
        "    length = max(len(s1_list),len(s2_list),len(s3_list))\n",
        "    l = [s1_list,s2_list,s3_list]\n",
        "    l2 = [str1,str2,str3]\n",
        "    #print(length)\n",
        "    list_of_zeros = [0]*length\n",
        "    #print(list_of_zeros)\n",
        "    max_list = [x for x in l if len(x) == length][0]\n",
        "    other = []\n",
        "    voting_list = [s1_list,s2_list,s3_list]\n",
        "    voting_dict = {}\n",
        "    for string in l2:\n",
        "      if string in voting_dict.keys():\n",
        "        voting_dict[string] = voting_dict[string]+1\n",
        "      else:\n",
        "        voting_dict[string] = 1\n",
        "    all_values = voting_dict.values()\n",
        "    max_value = max(all_values)\n",
        "    #print(voting_dict)\n",
        "    #print(max_value)    \n",
        "    if max_value >= 2:\n",
        "      final = [key for key in voting_dict if (voting_dict[key] == max_value)][0]\n",
        "      if final == 'not_applicable':\n",
        "        #print(final)\n",
        "        for i in l2:\n",
        "          if i !='not_applicable':\n",
        "            final = i\n",
        "        return final\n",
        "      else:\n",
        "        return final\n",
        "    else:\n",
        "      #print(max_list)\n",
        "      for li in voting_list:\n",
        "        #print(li)\n",
        "        for s in li:\n",
        "          #print(s)\n",
        "          p = max_list.index(s)\n",
        "          list_of_zeros[p] = list_of_zeros[p]+1\n",
        "          #print(p)\n",
        "          #print(list_of_zeros)\n",
        "      index_list = find_index(2,list_of_zeros)\n",
        "      #print(index_list)\n",
        "      st = index_list[0]\n",
        "      ed = index_list[-1]+1\n",
        "      #print(ed)\n",
        "      if st == ed:\n",
        "        final_list = max_list[st]\n",
        "      else:\n",
        "        final_list = max_list[st:ed]\n",
        "      final = ' '.join(final_list)\n",
        "      return final\n",
        "  except:\n",
        "      return str3\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_68n7TnM73Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "    #print(str2)\n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWPUJU3Q_Icq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final['selected_text_results_final'] = final.apply(lambda x: votes_and_select(x.selected_text_results_x, x.selected_text_results_y,x.selected_text_results), axis=1)\n",
        "final['j_score'] = final.apply(lambda x: jaccard(x.selected_text, x.selected_text_results_final), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MOXMO3VAKO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(final),final['j_score'].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5h3q91zA2cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}