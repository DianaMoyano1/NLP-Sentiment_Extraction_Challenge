{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble with highest prob & words count - Eman.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DianaMoyano1/NLP-Sentiment_Extraction_Challenge/blob/master/Ensemble_with_highest_prob_%26_words_count_Eman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrGR6ljGnRWL",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 1: Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SclTK2sEy2U",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#install the following first\n",
        "!pip install transformers==2.11.0 --quiet\n",
        "!pip install tensorflow==2.2.0 --quiet\n",
        "!pip install tensorboardX --quiet\n",
        "!pip install simpletransformers --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-f6h_O-ax7b",
        "colab_type": "text"
      },
      "source": [
        "### Setup NVIDIA APEX\n",
        "\n",
        "Tool to enable mixed precision training. More info here: https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EKbT79HZ1FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile setup.sh\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8BU4o8aAxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will take 10mins to run\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "\n",
        "!sh setup.sh --quiet\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sonPGlnWahCx",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6XzV6-3RTGe",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#Import packages\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from apex import amp\n",
        "from glob import glob\n",
        "import os\n",
        "from random import random\n",
        "from pathlib import Path\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TFBertModel, BertModel, DistilBertModel, XLNetModel, RobertaModel\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from os.path import join\n",
        "\n",
        "\n",
        "use_cuda = True ##If True, GPU will be used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPBTI365dJLo",
        "colab_type": "text"
      },
      "source": [
        "### Mount Your Own Gdrive\n",
        "\n",
        "Below command will require you to validate your account, and it will provide you with a temporary access code to paste in the required field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-bkv7WRK7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7T-lNV39yOJ",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94gEgYzgV72",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Before running below command, make sure you have...\n",
        "- Created a *'tweet-sentiment-extraction'* folder inside the *'Colab Notebooks'* directory\n",
        "- Uploaded the *train.csv* and *test.csv* files to the *'tweet-sentiment-extraction'* folder \n",
        "\n",
        "Finally, make sure you have a folder called *'models'* inside the *'tweet-sentiment-extraction'* directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1aa6YfTGJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/train.csv')\n",
        "test_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho6qQLOmzy7-",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data\n",
        "\n",
        "Split into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEEY7JDVBRrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnE_Tgqlcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop selected_text column from the validation dataset (it will be later compared to the ground truth)\n",
        "val_df_new = val_df.drop('selected_text', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8FMKmbQF7au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape)\n",
        "print(val_df_new.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBON4Ni8GSpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.array(train_df)\n",
        "val = np.array(val_df_new)\n",
        "test = np.array(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek9h3rTVxTlu",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Create list for training\n",
        "\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def find_all(input_str, search_str):\n",
        "    l1 = []\n",
        "    length = len(input_str)\n",
        "    index = 0\n",
        "    while index < length:\n",
        "        i = input_str.find(search_str, index)\n",
        "        if i == -1:\n",
        "            return l1\n",
        "        l1.append(i)\n",
        "        index = i + 1\n",
        "    return l1\n",
        "\n",
        "def do_qa_train(train):\n",
        "\n",
        "    output = []\n",
        "    for line in train:\n",
        "        context = line[1]\n",
        "\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        answers = []\n",
        "        answer = line[2]\n",
        "        if type(answer) != str or type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answer_starts = find_all(context, answer)\n",
        "        for answer_start in answer_starts:\n",
        "            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n",
        "            break\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "        \n",
        "    return output\n",
        "\n",
        "qa_train = do_qa_train(train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tT9xRQkx4HX",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Create val list\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def do_qa_val(val):\n",
        "    output = []\n",
        "    for line in val:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_val = do_qa_val(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47p9InteyPsa",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Create test list\n",
        "## Adapted from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def do_qa_test(test):\n",
        "    output = []\n",
        "    for line in test:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_test = do_qa_test(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFB0LNoZ9C-1",
        "colab_type": "text"
      },
      "source": [
        "### Initiate the SimpleTransformers Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln6FNmWRJlJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simpletransformers.question_answering import QuestionAnsweringModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DsYbQI18gP7",
        "colab_type": "text"
      },
      "source": [
        "### Create a Logging Module --> More info [here](https://realpython.com/python-logging/#:~:text=The%20Logging%20Module,-The%20logging%20module&text=It%20is%20used%20by%20most,homogeneous%20log%20for%20your%20application.&text=With%20the%20logging%20module%20imported,that%20you%20want%20to%20see.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7kc0kuO5oF4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Logs provide developers with an extra set of eyes that are constantly looking at the flow that an application is going through. They can store information, like which user or IP accessed the application.  \n",
        "\n",
        "With the logging module imported, you can use something called a “logger” to log messages that you want to see. By default, there are 5 standard levels indicating the severity of events.\n",
        "- DEBUG\n",
        "- INFO\n",
        "- WARNING\n",
        "- ERROR\n",
        "- CRITICAL\n",
        "\n",
        "In this case, we picked INFO and WARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-18PYUqo4yLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne55UzM9DppA",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model arguments and other files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ln-OCSbUtAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')\n",
        "train_df.to_csv(\"new_train_df\")\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XifqXffjlGqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This line creates a JSON file that is required when loading the model\n",
        "#with open('args_train.json', 'w') as fp: \n",
        "    #json.dump(args_train, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDE_EE42bEW1",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 3: Load and Evaluate a Richardson's Pre-Trained Models for Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pHXf7bq9Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = '/gdrive/My Drive/Colab Notebooks/Models For Ensemble' #Don't change\n",
        "NAME_OF_MODEL1 = 'Diana_bert-base-cased_A' #change\n",
        "MODEL_ARCHITECTURE1 = 'bert' #change\n",
        "\n",
        "FULL_PATH1 = join(ROOT, NAME_OF_MODEL1)\n",
        "\n",
        "#Change the workspace to the model folder\n",
        "%cd '{FULL_PATH1}' \n",
        "\n",
        "#Load the model's arguments list (required to setup the existing model) \n",
        "with open('args_train.json') as json_file: \n",
        "    train_args1 = json.load(json_file) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apdW5oFGuiXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model1 = QuestionAnsweringModel(MODEL_ARCHITECTURE1, 'outputs/', args=train_args1, use_cuda=use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA1GlPcrsV1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = '/gdrive/My Drive/Colab Notebooks/Models For Ensemble' #Don't change\n",
        "NAME_OF_MODEL2 = 'diana_distilbert-base-uncased-distilled-squad_A' # change\n",
        "MODEL_ARCHITECTURE2 = 'distilbert' #change\n",
        "\n",
        "FULL_PATH2 = join(ROOT, NAME_OF_MODEL2)\n",
        "\n",
        "#Change the workspace to the model folder\n",
        "%cd '{FULL_PATH2}' \n",
        "\n",
        "#Load the model's arguments list (required to setup the existing model) \n",
        "with open('args_train.json') as json_file: \n",
        "    train_args2 = json.load(json_file) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUWVc0S_ulDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model2 = QuestionAnsweringModel(MODEL_ARCHITECTURE2, 'outputs/', args=train_args2, use_cuda=use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UOQ4hTs4uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = '/gdrive/My Drive/Colab Notebooks/Models For Ensemble' #Don't change\n",
        "NAME_OF_MODEL3 = 'lucas_roberta-large_B' #change\n",
        "MODEL_ARCHITECTURE3 = 'roberta' #change\n",
        "\n",
        "FULL_PATH3 = join(ROOT, NAME_OF_MODEL3)\n",
        "\n",
        "#Change the workspace to the model folder\n",
        "%cd '{FULL_PATH3}' \n",
        "\n",
        "#Load the model's arguments list (required to setup the existing model) \n",
        "with open('args_train.json') as json_file: \n",
        "    train_args3 = json.load(json_file) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaLA-2ibEBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model3 = QuestionAnsweringModel(MODEL_ARCHITECTURE3, 'outputs/', args=train_args3, use_cuda=use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiDki8xbA4ZY",
        "colab_type": "text"
      },
      "source": [
        "#### Setup loaded model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZCmZyVANve",
        "colab_type": "text"
      },
      "source": [
        "Supported model types for Question&Answering:\n",
        "\n",
        "- ALBERT\n",
        "- BERT\n",
        "- DistilBERT\n",
        "- ELECTRA\n",
        "- XLM\n",
        "- XLNet\n",
        "\n",
        "Related link: https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOWk-YAeKw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val = loaded_model1.predict(qa_val)\n",
        "predictions_test = loaded_model1.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvqhWsD_y_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)\n",
        "#test\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QY1pQVoTKa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val2 = loaded_model2.predict(qa_val)\n",
        "predictions_test2 = loaded_model2.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnftsfJsbFlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val2 = pd.DataFrame.from_dict(predictions_val2)\n",
        "text_val2 = pd.DataFrame(predictions_val2[0])\n",
        "prob_val2 = pd.DataFrame(predictions_val2[1])\n",
        "prop1_val2 = prob_val2['probability'].tolist()\n",
        "prop2_val2 = pd.DataFrame(prop1_val2)\n",
        "text1_val2 = text_val2['answer'].tolist()\n",
        "text2_val2 = pd.DataFrame(text1_val2)\n",
        "#test\n",
        "predictions_df_test2 = pd.DataFrame.from_dict(predictions_test2)\n",
        "text_test2 = pd.DataFrame(predictions_test2[0])\n",
        "prob_test2 = pd.DataFrame(predictions_test2[1])\n",
        "prop1_test2 = prob_test2['probability'].tolist()\n",
        "prop2_test2 = pd.DataFrame(prop1_test2)\n",
        "text1_test2 = text_test2['answer'].tolist()\n",
        "text2_test2 = pd.DataFrame(text1_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1m2Byd5TKOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val3 = loaded_model3.predict(qa_val)\n",
        "predictions_test3 = loaded_model3.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYgWwk94bFdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Output with highest prob - Val and Test\n",
        "#val\n",
        "predictions_df_val3 = pd.DataFrame.from_dict(predictions_val3)\n",
        "text_val3 = pd.DataFrame(predictions_val3[0])\n",
        "prob_val3 = pd.DataFrame(predictions_val3[1])\n",
        "prop1_val3 = prob_val3['probability'].tolist()\n",
        "prop2_val3 = pd.DataFrame(prop1_val3)\n",
        "text1_val3 = text_val3['answer'].tolist()\n",
        "text2_val3 = pd.DataFrame(text1_val3)\n",
        "#test\n",
        "predictions_df_test3 = pd.DataFrame.from_dict(predictions_test3)\n",
        "text_test3 = pd.DataFrame(predictions_test3[0])\n",
        "prob_test3 = pd.DataFrame(predictions_test3[1])\n",
        "prop1_test3 = prob_test3['probability'].tolist()\n",
        "prop2_test3 = pd.DataFrame(prop1_test3)\n",
        "text1_test3 = text_test3['answer'].tolist()\n",
        "text2_test3 = pd.DataFrame(text1_test3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnPM7OF9eQAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()\n",
        "sub_val_df2 = val_df.copy()\n",
        "sub_test_df2 = test_df.copy()\n",
        "sub_val_df3 = val_df.copy()\n",
        "sub_test_df3 = test_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HS_Rxvugnb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create files to export \n",
        "sub_val_df['selected_text_results'] = text2_val[0].values\n",
        "sub_test_df['selected_text_results'] = text2_test[0].values\n",
        "sub_val_df2['selected_text_results2'] = text2_val2[0].values\n",
        "sub_test_df2['selected_text_results2'] = text2_test2[0].values\n",
        "sub_val_df3['selected_text_results3'] = text2_val3[0].values\n",
        "sub_test_df3['selected_text_results3'] = text2_test3[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx-5JqBez1L_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df['prob'] = prop2_val[0].values\n",
        "sub_test_df['prob'] = prop2_test[0].values\n",
        "sub_val_df2['prob2'] = prop2_val2[0].values\n",
        "sub_test_df2['prob2'] = prop2_test2[0].values\n",
        "sub_val_df3['prob3'] = prop2_val3[0].values\n",
        "sub_test_df3['prob3'] = prop2_test3[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXKogfZ6icjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df = sub_val_df[['textID','selected_text','selected_text_results', 'prob']]\n",
        "sub_val_df2 = sub_val_df2[['textID','selected_text','selected_text_results2','prob2']]\n",
        "sub_val_df3 = sub_val_df3[['textID','selected_text','selected_text_results3', 'prob3']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ym84Sj5iz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = sub_val_df.merge(sub_val_df2,on=['textID','selected_text'],how='left')\n",
        "final = final.merge(sub_val_df3,on=['textID','selected_text'],how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JU2y3sM_v0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.head(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_WRrJDcwrpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(lines):\n",
        "  stop_words = ['_']\n",
        "  results = []\n",
        "  for text in lines:\n",
        "    tmp = text.split(' ')\n",
        "    for x in range(0, len(tmp)):\n",
        "      for st_w in stop_words:\n",
        "        if st_w in tmp[x]:\n",
        "          tmp[x] = ''\n",
        "    results.append(\" \".join(tmp))\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LD8Y072wwGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_stop_words(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vLGSElwd3HE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNRrHZy4jDJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#by prob\n",
        "selected_text_results_highest_prob = [] \n",
        "for i in np.arange(0,len(final)):\n",
        "  max_prob = [final['prob'].iloc[i], final['prob2'].iloc[i], final['prob3'].iloc[i]]\n",
        "  answers = [final['selected_text_results'].iloc[i], final['selected_text_results2'].iloc[i], final['selected_text_results3'].iloc[i]]\n",
        "  highest_prob_answer = answers[np.argmax(max_prob)]\n",
        "  selected_text_results_highest_prob.append(highest_prob_answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak_2pJmxreUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = final['selected_text_results'].iloc[1].split()\n",
        "b = final['selected_text_results2'].iloc[1].split()\n",
        "c = final['selected_text_results3'].iloc[1].split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rUGvVb_0-Pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = a+b+c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CKIktgQ1Zl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "def top5_words(text):\n",
        "    counts = collections.Counter(text)\n",
        "    return counts.most_common()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHKrA8eg1k5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "myDict = Counter(test)\n",
        "res = Counter({k: v for k, v in myDict.items() if v > 1})\n",
        "list_test = []\n",
        "for key in res.keys():\n",
        "  list_test.append(key)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OThfRhMgBFZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#by word count\n",
        "selected_text_results_unique_words = []\n",
        "\n",
        "for i in np.arange(0,len(final)):\n",
        "   a = final['selected_text_results'].iloc[i].split()\n",
        "   b = final['selected_text_results2'].iloc[i].split()\n",
        "   c = final['selected_text_results3'].iloc[i].split()\n",
        "   unique_list = a + b + c \n",
        "   myDict = Counter(unique_list)\n",
        "   res = Counter({k: v for k, v in myDict.items() if v > 1})\n",
        "   list_keys = []\n",
        "   for key in res.keys():\n",
        "     list_keys.append(key)\n",
        "   unique_sent = ' '.join(list_keys) \n",
        "   selected_text_results_unique_words.append(unique_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL6oKoU4y1iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final['selected_text_results_highest_prob'] = selected_text_results_highest_prob\n",
        "final['selected_text_results_unique_words'] = selected_text_results_unique_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_68n7TnM73Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "    #print(str2)\n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSbxTQT-oXVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 'are you good today'\n",
        "b = 'are you good fine'\n",
        "c = 'are you good today ok tomorrow'\n",
        "print(jaccard(a,b))\n",
        "print(jaccard(a,c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWPUJU3Q_Icq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Obtain JS for the entire set\n",
        "results = []\n",
        "for i in range(len(final)):\n",
        "    score = jaccard(final['selected_text'].iloc[i], final['selected_text_results_highest_prob'].iloc[i])\n",
        "    results.append(score)\n",
        "    \n",
        "Jaccard_score = sum(results) / len(results)\n",
        "Jaccard_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqZNmkXcbISp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Obtain JS for the entire set\n",
        "results = []\n",
        "for i in range(len(final)):\n",
        "    score = jaccard(final['selected_text'].iloc[i], final['selected_text_results_unique_words'].iloc[i])\n",
        "    results.append(score)\n",
        "    \n",
        "Jaccard_score = sum(results) / len(results)\n",
        "Jaccard_score"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}