{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  NLP QA Kaggle distilbert Cases.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DianaMoyano1/NLP-Sentiment_Extraction_Challenge/blob/master/Workstream_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SclTK2sEy2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install the following first\n",
        "!pip install transformers==2.10.0 --quiet\n",
        "!pip install tensorflow==2.2.0 --quiet\n",
        "!pip install tensorboardX --quiet\n",
        "!pip install simpletransformers --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EKbT79HZ1FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile setup.sh\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8BU4o8aAxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will take 10mins to run\n",
        "!sh setup.sh --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-bkv7WRK7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##To delete. Reason--> No need for it since we are using URL\n",
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6XzV6-3RTGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from apex import amp\n",
        "from glob import glob\n",
        "import os\n",
        "from random import random\n",
        "from pathlib import Path\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BertTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TFBertModel, BertModel, DistilBertModel, XLNetModel, RobertaModel\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Er9fLjNWYVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url1 = 'https://raw.githubusercontent.com/DianaMoyano1/MongoDB-in-R/master/train.csv'\n",
        "url2 = 'https://raw.githubusercontent.com/DianaMoyano1/MongoDB-in-R/master/test.csv'\n",
        "url3 = 'https://raw.githubusercontent.com/DianaMoyano1/MongoDB-in-R/master/sample_submission.csv'\n",
        "train_df = pd.read_csv(url1)\n",
        "test_df = pd.read_csv(url2)\n",
        "sub_df = pd.read_csv(url3)\n",
        "\n",
        "\n",
        "use_cuda = True # whether to use GPU or not"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1aa6YfTGJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## To delete. Reason --> done in above cell with URL\n",
        "\"\"\"train_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/train.csv')\n",
        "test_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/test.csv')\n",
        "sub_df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/sample_submission.csv')\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "SETTINGS\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEEY7JDVBRrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmnE_Tgqlcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop selected_text column from table\n",
        "val_df_new = val_df.drop('selected_text', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8FMKmbQF7au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape)\n",
        "print(val_df_new.shape)\n",
        "print(test_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBON4Ni8GSpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.array(train_df)\n",
        "val = np.array(val_df_new)\n",
        "test = np.array(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvWbeYDGPT-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create list for training\n",
        "\n",
        "## Adpated from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\n",
        "def find_all(input_str, search_str):\n",
        "    l1 = []\n",
        "    length = len(input_str)\n",
        "    index = 0\n",
        "    while index < length:\n",
        "        i = input_str.find(search_str, index)\n",
        "        if i == -1:\n",
        "            return l1\n",
        "        l1.append(i)\n",
        "        index = i + 1\n",
        "    return l1\n",
        "\n",
        "def do_qa_train(train):\n",
        "\n",
        "    output = []\n",
        "    for line in train:\n",
        "        context = line[1]\n",
        "\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        answers = []\n",
        "        answer = line[2]\n",
        "        if type(answer) != str or type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answer_starts = find_all(context, answer)\n",
        "        for answer_start in answer_starts:\n",
        "            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n",
        "            break\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "        \n",
        "    return output\n",
        "\n",
        "qa_train = do_qa_train(train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD6Jk6WXHHx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create val list\n",
        "def do_qa_val(val):\n",
        "    output = []\n",
        "    for line in val:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_val = do_qa_val(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nUa3ClTU3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creat test list\n",
        "def do_qa_test(test):\n",
        "    output = []\n",
        "    for line in test:\n",
        "        context = line[1]\n",
        "        qas = []\n",
        "        question = line[-1]\n",
        "        qid = line[0]\n",
        "        if type(context) != str or type(question) != str:\n",
        "            print(context, type(context))\n",
        "            print(answer, type(answer))\n",
        "            print(question, type(question))\n",
        "            continue\n",
        "        answers = []\n",
        "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
        "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
        "        output.append({'context': context.lower(), 'qas': qas})\n",
        "    return output\n",
        "\n",
        "qa_test = do_qa_test(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-18PYUqo4yLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVp2dmsADKkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /gdrive/My Drive/Colab Notebooks/tweet-sentiment-extraction/Dist_Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln6FNmWRJlJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from simpletransformers.question_answering import QuestionAnsweringModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlWY8Y7MYSmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args_train={'reprocess_input_data': True,\n",
        "'overwrite_output_dir': True,\n",
        "'learning_rate': 5e-5,\n",
        "'num_train_epochs': 3,\n",
        "'max_seq_length': 192,\n",
        "'doc_stride': 64,\n",
        "'fp16': False,\n",
        "}\n",
        "\n",
        "model = QuestionAnsweringModel('distilbert', 'distilbert-base-cased', args=args_train, use_cuda=use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdo6wnSdYJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train_model(qa_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttTEa5vskmCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_val = model.predict(qa_val)\n",
        "predictions_test = model.predict(qa_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb_ZrfqQNkHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#val\n",
        "predictions_df_val = pd.DataFrame.from_dict(predictions_val)\n",
        "text_val = pd.DataFrame(predictions_val[0])\n",
        "prob_val = pd.DataFrame(predictions_val[1])\n",
        "prop1_val = prob_val['probability'].tolist()\n",
        "prop2_val = pd.DataFrame(prop1_val)\n",
        "text1_val = text_val['answer'].tolist()\n",
        "text2_val = pd.DataFrame(text1_val)\n",
        "#test\n",
        "predictions_df_test = pd.DataFrame.from_dict(predictions_test)\n",
        "text_test = pd.DataFrame(predictions_test[0])\n",
        "prob_test = pd.DataFrame(predictions_test[1])\n",
        "prop1_test = prob_test['probability'].tolist()\n",
        "prop2_test = pd.DataFrame(prop1_test)\n",
        "text1_test = text_test['answer'].tolist()\n",
        "text2_test = pd.DataFrame(text1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1NXIUmhU64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df = val_df.copy()\n",
        "sub_test_df = test_df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSOuQa19ntpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_val_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUB5FeXMhXbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create files to export \n",
        "sub_val_df['selected_text_results'] = text2_val[0].values\n",
        "sub_test_df['selected_text_results'] = text2_test[0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrjMaEA8m_gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ln-OCSbUtAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "sub_val_df.to_csv('sub_val.csv') \n",
        "files.download('sub_val.csv')\n",
        "sub_test_df.to_csv('sub_test.csv') \n",
        "files.download('sub_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNcF8mn0XdO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.to_csv(\"new_train_df\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}